---
title: "[Paper Review] Clean-GS: Semantic Mask-Guided Pruning for 3D Gaussian Splatting"
date: "2026-01-11 18:00:00 +0900"
categories: ["Paper Review","3D Vision"]
tags: ["Paper Review"]
math: true
---

Author: [Subhankar Mishra](https://arxiv.org/search/cs?searchtype=author&query=Mishra,+S)

[[github]](https://github.com/smlab-niser/clean-gs)[[paper]](https://arxiv.org/abs/2601.00913)



![Figure 1](\assets\img\Paper-Review\Clean-GS\Figure1.webp)

### 1 Introduction

---

3DGS는 야외장면에 대해서 수십만 개의 floater를 생성합니다. 이러한 floater는 background와 결합하여 object를 가리고 model 크기를 증가시킵니다. 문화유산 아카이브,AR/VR에는 깨끗한 객체를 분리하는 것이 중요하며 웹 배포에서는 작은 model 크기를 요구합니다. 그래서 Clean-GS는 floater를 제거하고 객체를 분리하는 semantic mask-guided pruning method를 제안합니다.

해당 method는 3 stage로 구성됩니다.

1. whitelist filtering은 environment과 먼 floater를 제거
2. depth-buffering을 사용하여 color validation을 통해 객체 주위의 가시적인 artifact를 제거
3. neighbor-based(k-NN)을 이용한 outlier removal로 고립된 floater를 제거

sparse semantic mask(302개 뷰 중 단 3개)에 걸친 Spatial consistency는 효과적인 floater제거를 위한 충분한 신호를 제공합니다.

Clean-GS는 객체 디테일을 보존하면서 60~80% 압축률을 달성했습니다. 해당 method는 sparse supervision에서 특히 효과적입니다.

### 3 Method

---

Clean-GS의 목표는 객체 이미지에 대해 trained 3DGS model \[\{G_i\}_{i=1}^{N}\] 과 binary semantic mask \[\{M_j\}_{j=1}^{M}\] 가 주어지면 객체 가우시안 \[\{G'_k\}_{k=1}^{N'}\] 을 도출하는 것입니다.

#### 3.1 Stage 1: Whitelist Filtering

첫번째는 masked view에서 객체 영역에 투영되지 않는 모든 가우시안을 제거합니다. 

각각의 가우시안 \[g_i\] 는  위치 \[\mathbf{x}_i \in \mathbb{R}^3\] 를 가지며, 각각의 카메라 \[j\] 는 내부 파라미터 \[K_j\] ,  회전 행렬 \[R^{(j)}_{\mathrm{c2w}}\] 이동 행렬 \[\mathbf{t}^{(j)}_{\mathrm{c2w}}\] 을 가집니다.

2D 투영을 계산하기 위한 식은 다음과 같습니다.
$$
\mathbf{R}_{w2c}^{(j)} = \left(\mathbf{R}_{c2w}^{(j)}\right)^T, \quad \mathbf{t}_{w2c}^{(j)} = -\mathbf{R}_{w2c}^{(j)} \mathbf{t}_{c2w}^{(j)}
$$

$$
\mathbf{x}_{\mathit{cam}} = \mathbf{R}_{w2c}^{(j)}\mathbf{x}_i + \mathbf{t}_{w2c}^{(j)}
$$

$$
d = \mathbf{x}_{\mathit{cam}}[2], \quad \mathbf{u} = \frac{\mathbf{K}_j \mathbf{x}_{\mathit{cam}}}{d}
$$

\[\mathbf{u} = [u, v]^{\top}\] 은 pixel coordinates이며 \[d\]은 depth 를 의미합니다. 만약 \[d<=0\] 이거나 \[u\] 가 image 밖이라면 projection을 하지 않습니다. 여기서 \[x_{cam}\] 은 카메라 좌표계에서 본 3D 점 \[x\]를 의미하며 [2]는 z축을 의미합니다. 

해당 수식이 이해가 되지 않는다면 [Pinhole Camera Model](https://woosunghyeon03.github.io/posts/pinhole-camera-model/) 해당 글을 참고해주세요.

**Whitelist Construction** : 각각의 Gaussian이 마스크의 객체 영역에 투영되었는지 확인합니다.
$$
w_i = \bigvee_{j=1}^{M} \ ⊮\left[ M_j(\mathbf{u}_i^{(j)}) > 0 \right]
$$
여기서 ⊮[·]는 indicator function이며  \[\mathbf{u}^{(j)}_i\] 는 카메라 \[j\[로부터 가우시안 \[g_i\]를 투영하는 픽셀 좌표입니다. 그래서 whitelist에 포함하는 모든 Gaussian은 1로 간주합니다. Gaussian이 어떠한 masked view에도 투영되지 못했다면 background에 해당하므로 지웁니다.

#### 3.2 Stage 2: Color Validation

아직 객체 주위의 artifact는 여전히 남아있지만 해당 floater는 객체와 color가 다릅니다. 그래서 depth buffering을 이용하여 color를 검증합니다.

**Depth Buffering** : 각각의 masked view에서 whitelisted Gaussian만을 depth buffering과 함께 렌더링합니다. 각 pixel p에서 depth가 가장 가까운 Gaussian만 남깁니다.  
$$
g^*(\mathbf{p}) = \arg \min_{i \in W, \mathbf{u}_i^{(j)} = \mathbf{p}} d_i^{(j)}
$$
\[W\]은 whitelist set이며 \[d_i^{(j)}\]는 카메라 \[j\]에서의 바라본 Gaussian \[i\]의  depth 입니다.

**Color Matching**: pixel \[p\]에서 가장 가까운 Gaussian \[i\]에 대하여 SH coefficients로부터의 Color(RGB)를 계산합니다. 
$$
\mathbf{c}_i = C_0 \cdot \mathbf{f}_{dc}^{(i)} + 0.5
$$
\[C_0\]=0.28209479는 SH의 정규화 상수로서 SH를 사용할 때 항상 곱해지는 상수이며 \[f^(i)_{dc}\]는 DC component라고 해서 이 Gaussian을 어느 방향에서 보든 공통적으로 가지는 색 성분입니다. 여기서 0.5를 더하는 이유는 SH계수가 음수도 가능하지만 보통 [0,1]범위가 좋기 때문에 0.5를 더함으로써 양수 영역으로 이동시킵니다. 해당 색을 image로부터 예측된 색상 \[c_{mask}(p)\] 와 비교합니다.
$$
\delta_i = \|\mathbf{c}_i - \mathbf{c}_{\text{mask}(\mathbf{p})}\|_2
$$
**Filtering** : 다음과 같은 경우에만 Gaussian \[i\]를 유지합니다.

어떤 masked view에서도 전면 레이어로 렌더링 되지 않은 경우 또는 렌더링된 뷰 중 적어도 하나에서 \[δ_i < τ\]를 만족하는 경우입니다. 하지만 이 방법은 color가 명확하게 불일치할때만 제거하는 보수적인 방법입니다.



#### 3.3 Stage 3: Outlier Removal

이전의  method를 적용한 뒤 남아있는 artifact는 3D 공간에서 고립되는 경향이 있습니다. 해당 section에서는 outlier를 제거하는 3가지 전략을 제공합니다.

**Spatial Outlier Removal** : scene center로부터 먼 Gaussian을 제거합니다.
$$
\mathbf{c} = \frac{1}{|S|} \sum_{i \in S} \mathbf{x}_i, \quad d_i = \|\mathbf{x}_i - \mathbf{c}\|_2
$$
\[S\]는 남아있는 Gaussian입니다. 남아있는 Gaussian들의 평균 위치를 center로 하여 center로 정의하며 \[d_i > percentile_{(d, pspatial)}\] 으로  \[p_{spatial}\] = 99 설정하여 center에서 멀리 떨어진 하위 1%를 제거합니다.

**Neighbor-Based Outlier Removal**: knn neighbor에서 떨어진 gaussian을 제거합니다.
$$
\bar{d}_i = \frac{1}{k} \sum_{j \in \text{kNN}(i,k)} \Vert \mathbf{x}_i - \mathbf{x}_j \Vert_2
$$
\[\bar{d}_i > \operatorname{percentile}(\bar{d},\, p_{\text{neighbor}})\] 이며 \[k = 10\] , \[p_neighbor=95\]로 설정하여 각각의 Gaussian에서 가장 근접한 Gaussian 10개의 거리의 평균을 계산하여 평균의 하위 5%에 해당하는 Gaussian을 제거합니다.

**Multi-View Consistency**: 이전에는 1개의 view에서 나타나도록 했지만 해당 stage에서는 m가의 view에서 나타나도록 합니다.
$$
w_{i} = \left[ \sum_{j=1}^{M} ⊮ \left[ \mathcal{M}_{j} \left( \mathbf{u}_{i}^{(j)} \right) > 0 \right] \geq m \right]
$$
이는 artifact와 같이 우연히 하나의 view에서 나타는 gaussian을 제거합니다.



#### 3.4 Implementation Details

 **Parallelization**: 96 CPU core로 멀티프로세싱을 이용해 view별로 병렬처리를 합니다. 각 worker는 하나의 view를 독립적으로 처리하며, projection 및 color matching을 계산합니다. 결과는 boolean operations(whitelist) 또는  counting(multi-view)로 집계됩니다.

**Resolution Handling**: COLMAP이 카메라 왜곡을 보정해주는 것은 이미지 해상도를 변경할 수 있습니다. projection 이전에 camera parameters에 맞도록 mask 크기를 조정합니다.

**Parameters**: color threshold \[τ=0.4\](RGB공간에 대한 Euclidean distance), multi-view mode에서의 minimum views \[m = 2\] 입니다. 

### 4 Experiments

---

#### 4.1 Experimental Setup

**Datasets**: 두개의 조형물에 대해서 평가합니다.

- Temple: T&T데이터셋의 302장의 image로 구성된 야외 사원 구조물이며 SAM을 활용하여 3개의 mask만 활용했습니다. 원본 모델: 525,717 Gaussians, 125MB
- Isha Statue: 103장의 image로 구성된 대규모 야외 조각상으로 SAM으로 Mask를 생성하였습니다. 원본 모델: 1,112,566 Gaussians, 263.6MB

**Variants**

- Original: Unmodified 3DGS model
- Basic: Whitelist + Color validation only (stages 1-2)
- Clean-GS: Full method with neighbor-based outlier removal (stages 1-3, recommended)
- Clean-GS (combined): All outlier removal strategies (most aggressive)

**Note** : 배경제거를 목표로 하기때문에 PSNR/SSIM은 평가하지 않습니다

![Table 1](\assets\img\Paper-Review\Clean-GS\Table1.webp)

![Table 2](\assets\img\Paper-Review\Clean-GS\Table2.webp)

![Figure 3](\assets\img\Paper-Review\Clean-GS\Figure3.webp)

![Figure 2](\assets\img\Paper-Review\Clean-GS\Figure2.webp)

Multi-view consistency는 많은 마스크가 존재할 때는 효과적이지만 sparse supervision에서는 너무 많은 Gaussian을 제거합니다.

모든 전략을 결합하면 21% Gaussian을 제거하지만 과도한 pruning의 위험이 있습니다.

**4.7 Limitation**

- 객체가 모든 view에서 부분적으로 가려져있는 경우 잘못 제거 될 수 있습니다

- 배경이 객체와 유사한 색상을 가질 때 일부 배경 Gaussian이 보존될 수 있으나 KNN removal가 도움이 됩니다.
- 멀티코어CPU가 필요합

